{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SureStart Day 5: Action Item"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the data\n\nimport json\n\ndef parse_data(file):\n    for l in open(file,'r'):\n        yield json.loads(l)\n\ndata = list(parse_data('/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json'))\ndata[0]","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n 'is_sarcastic': 0}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dataframe\ndf = pd.read_json(\"../input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\", lines=True)\ndf.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                        article_link  \\\n0  https://www.huffingtonpost.com/entry/versace-b...   \n1  https://www.huffingtonpost.com/entry/roseanne-...   \n2  https://local.theonion.com/mom-starting-to-fea...   \n3  https://politics.theonion.com/boehner-just-wan...   \n4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n\n                                            headline  is_sarcastic  \n0  former versace store clerk sues over secret 'b...             0  \n1  the 'roseanne' revival catches up to our thorn...             0  \n2  mom starting to fear son's web series closest ...             1  \n3  boehner just wants wife to listen, not come up...             1  \n4  j.k. rowling wishes snape happy birthday in th...             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_link</th>\n      <th>headline</th>\n      <th>is_sarcastic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n      <td>former versace store clerk sues over secret 'b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n      <td>the 'roseanne' revival catches up to our thorn...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n      <td>mom starting to fear son's web series closest ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://politics.theonion.com/boehner-just-wan...</td>\n      <td>boehner just wants wife to listen, not come up...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n      <td>j.k. rowling wishes snape happy birthday in th...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(26709, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['is_sarcastic'].value_counts()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"0    14985\n1    11724\nName: is_sarcastic, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import `train_test_split` from `sklearn.model_selection`\nfrom sklearn.model_selection import train_test_split\n\n# Import TfidfVectorizer: transforms text to feature vectors that can be used as input to estimator\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Specify the data \nvectorizer = TfidfVectorizer(max_features=1000, use_idf=False)\nheadlines = [i['headline'] for i in data]\n\n# Create x variable\nX = vectorizer.fit_transform(headlines).toarray()\n\n# Create y variable (target labels)\ny=df['is_sarcastic'].values\n\n# Split the data up in train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build a Sequential Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import `Sequential` from `keras.models`\nfrom keras.models import Sequential\n\n# Import `Dense` from `keras.layers`\nfrom keras.layers import Dense\n\n# Initialize the constructor\nmodel = Sequential()\n\n# Add an input layer \nmodel.add(Dense(32, activation='relu', input_shape=(1000,)))\n\n# Add one hidden layer \nmodel.add(Dense(4, activation='relu'))\n\n# Add an output layer \nmodel.add(Dense(1, activation='sigmoid'))","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compile & Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model \n\n# with adam optimizer and the binary_crossentropy loss function\n# can monitor the accuracy during the training by passing ['accuracy'] to the metrics argument\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# Model Summary\nmodel.summary()","execution_count":18,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 32)                32032     \n_________________________________________________________________\ndense_1 (Dense)              (None, 4)                 132       \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 5         \n=================================================================\nTotal params: 32,169\nTrainable params: 32,169\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model\n\nmodel.fit(X_train, y_train,epochs=25, batch_size=300, verbose=1)","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch 1/25\n72/72 [==============================] - 1s 3ms/step - loss: 0.2551 - accuracy: 0.8958\nEpoch 2/25\n72/72 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.8970\nEpoch 3/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.9012\nEpoch 4/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.9026\nEpoch 5/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2372 - accuracy: 0.9065\nEpoch 6/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.9099\nEpoch 7/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9130\nEpoch 8/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9159\nEpoch 9/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9144\nEpoch 10/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9207\nEpoch 11/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9239\nEpoch 12/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9214\nEpoch 13/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9289\nEpoch 14/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9272\nEpoch 15/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9307\nEpoch 16/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9341\nEpoch 17/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1828 - accuracy: 0.9362\nEpoch 18/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.9360\nEpoch 19/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9402\nEpoch 20/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1720 - accuracy: 0.9409\nEpoch 21/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9408\nEpoch 22/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9445\nEpoch 23/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9485\nEpoch 24/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9478\nEpoch 25/25\n72/72 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9479\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f6994584090>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# **Evaluate Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the labels (test the model)\ny_pred = model.predict(X_test)\n\n# Evaluate the model\nscore = model.evaluate(X_test, y_test,verbose=1)\n\n# score is a list that holds the combination of the loss and the accuracy\nprint(score)","execution_count":20,"outputs":[{"output_type":"stream","text":"167/167 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.7894\n[0.5848135352134705, 0.7894046902656555]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the modules for evaluation metrics from `sklearn.metrics`\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n\n# Confusion matrix\nconfusion_matrix(y_test, y_pred.round())","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"array([[2463,  533],\n       [ 592, 1754]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Precision: a measure of a classifier’s exactness; the higher the precision, the more accurate the classifier\nprecision = precision_score(y_test, y_pred.round())\n\n# Recall: a measure of a classifier’s completeness; the higher the recall, the more cases the classifier covers\nrecall = recall_score(y_test, y_pred.round())\n\n# F1 score: a weighted average of precision and recall\nf1_score = f1_score(y_test,y_pred.round())\n\n# Print all values\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1_score}\")","execution_count":22,"outputs":[{"output_type":"stream","text":"Precision: 0.7669435942282467\nRecall: 0.7476555839727195\nF1 Score: 0.7571767753075762\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}