{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Upsampling Tutorial.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3t5A6OD019-"
      },
      "source": [
        "# Upsampling Tutorial\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3hk2vYP0x2M"
      },
      "source": [
        "## Worked Example Using the UpSampling2D Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyQ8HPPi1q_e"
      },
      "source": [
        "# example of using the upsampling layer\r\n",
        "from numpy import asarray\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import UpSampling2D"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "864RQFFN1D2h",
        "outputId": "dc7d7da0-cd0d-4aff-e2cc-4e2ad9cbb533"
      },
      "source": [
        "# define input data\r\n",
        "X = asarray([[1, 2],\r\n",
        "\t\t\t [3, 4]])\r\n",
        "\r\n",
        "# show input data for context\r\n",
        "print(X)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJxHnvVi1Oq9"
      },
      "source": [
        "# reshape input data into one sample a sample with a channel\r\n",
        "X = X.reshape((1, 2, 2, 1))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmIWb9bu1XqE"
      },
      "source": [
        "The model has only the UpSampling2D layer which takes 2×2 grayscale images as input & outputs the result of the upsampling operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fubt15_01UXh",
        "outputId": "511802bd-c4bd-4da3-f3d2-158b1e050ba5"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(UpSampling2D(input_shape=(2, 2, 1)))\r\n",
        "\r\n",
        "# summarize the model\r\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d (UpSampling2D) (None, 4, 4, 1)           0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C1ctAwo1aBK"
      },
      "source": [
        "# make a prediction with the model - upsample a provided input image\r\n",
        "yhat = model.predict(X)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG7XkPgA1i1C",
        "outputId": "62d43719-29d3-482d-96a8-f3595b5c52b7"
      },
      "source": [
        "# reshape output to remove channel to make printing easier\r\n",
        "yhat = yhat.reshape((4, 4))\r\n",
        "\r\n",
        "# summarize output\r\n",
        "print(yhat)\r\n",
        "\r\n",
        "# We can see that it will output a 4×4 result as we expect, and importantly, the layer has no parameters or model weights. \r\n",
        "# This is because it is not learning anything; it is just doubling each row and column for our input data."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 2. 2.]\n",
            " [1. 1. 2. 2.]\n",
            " [3. 3. 4. 4.]\n",
            " [3. 3. 4. 4.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMd0NrjM2dQS"
      },
      "source": [
        "## Simple Generator Model With the UpSampling2D Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uztD24b77Dkm"
      },
      "source": [
        "The UpSampling2D layer is not able to fill in useful detail in the upsampling operation. To be useful in a GAN, each UpSampling2D layer must be followed by a Conv2D layer that will learn to interpret the doubled input and be trained to translate it into meaningful detail.\r\n",
        "\r\n",
        "In this example, our little GAN generator model must produce a 10×10 image and take a 100 element vector from the latent space as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yR4r7QH633j"
      },
      "source": [
        "# example of using upsampling in a simple generator model\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Reshape\r\n",
        "from keras.layers import UpSampling2D\r\n",
        "from keras.layers import Conv2D"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8hhrmvf7Zjz"
      },
      "source": [
        "\r\n",
        "A Dense fully connected layer can be used to interpret the input vector and create a sufficient number of activations (outputs) that can be reshaped into a low-resolution version of our output image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj9SJr1e6Ucz"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# define input shape, output enough activations for 128 versions of a 5x5 image\r\n",
        "model.add(Dense(128 * 5 * 5, input_dim=100))\r\n",
        "\r\n",
        "# reshape vector of activations into 128 feature maps with 5x5\r\n",
        "model.add(Reshape((5, 5, 128)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1PHZj9A8DV4"
      },
      "source": [
        "The upsampled feature maps can be interpreted and filled in with hopefully useful detail by a Conv2D layer, which has a single feature map as output to create the single image we require."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv9Gc70k6tPA",
        "outputId": "ffd4bcb1-256f-45fe-911f-1542f545bea1"
      },
      "source": [
        "# double input from 128 5x5 to 1 10x10 feature map\r\n",
        "model.add(UpSampling2D())\r\n",
        "\r\n",
        "# fill in detail in the upsampled feature maps\r\n",
        "model.add(Conv2D(1, (3,3), padding='same'))\r\n",
        "\r\n",
        "# summarize model\r\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3200)              323200    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 10, 10, 1)         1153      \n",
            "=================================================================\n",
            "Total params: 324,353\n",
            "Trainable params: 324,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTA_GLdDo9AF"
      },
      "source": [
        "We can see that the Dense layer outputs 3,200 activations that are then reshaped into 128 feature maps with the shape 5×5.\r\n",
        "\r\n",
        "The widths and heights are doubled to 10×10 by the UpSampling2D layer, resulting in a feature map with quadruple the area.\r\n",
        "\r\n",
        "Finally, the Conv2D processes these feature maps and adds in detail, outputting a single 10×10 image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVrdVNy78UMV"
      },
      "source": [
        "## Worked Example Using the Conv2DTranspose Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBbKT9e195Z_"
      },
      "source": [
        "# example of using the transpose convolutional layer\r\n",
        "from numpy import asarray\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2DTranspose"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEMIZY4R8ZAs",
        "outputId": "bab670ca-f664-4d52-a927-ab07e0236b8a"
      },
      "source": [
        "# define input data\r\n",
        "X = asarray([[1, 2],\r\n",
        " [3, 4]])\r\n",
        "\r\n",
        "# show input data for context\r\n",
        "print(X)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JsWgIsO9GCo"
      },
      "source": [
        "# reshape input data into one sample a sample with a channel\r\n",
        "X = X.reshape((1, 2, 2, 1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_7rOt0d9LKd"
      },
      "source": [
        "The model we define has only the Conv2DTranspose layer, which takes 2×2 grayscale images as input directly and outputs the result of the operation. It both upsamples and performs a convolution, so we must specify both the number of filters and the size of the filters.\r\n",
        "\r\n",
        "Additionally, we must specify a stride of (2,2) because the upsampling is achieved by the stride behavior of the convolution on the input, and doing so has the effect of spacing out the input. Specifically, rows and columns of 0.0 values are inserted to achieve the desired stride."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNcj0gEa9IP3",
        "outputId": "42358cc7-8b51-455d-d9bf-b07a075cebd7"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# one filter, with a 1×1 kernel and a stride of 2×2 so that the 2×2 input image is upsampled to 4×4.\r\n",
        "model.add(Conv2DTranspose(1, (1,1), strides=(2,2), input_shape=(2, 2, 1)))\r\n",
        "\r\n",
        "# summarize the model\r\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_transpose (Conv2DTran (None, 4, 4, 1)           2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGFglSIt9loW"
      },
      "source": [
        "# define weights that they do nothing\r\n",
        "weights = [asarray([[[[1]]]]), asarray([0])]\r\n",
        "\r\n",
        "# store the weights in the model\r\n",
        "model.set_weights(weights)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofnf6LMd9xT2",
        "outputId": "4d31d3a1-7ecc-44ad-d7b6-c76ba43889be"
      },
      "source": [
        "# make a prediction with the model\r\n",
        "yhat = model.predict(X)\r\n",
        "\r\n",
        "# reshape output to remove channel to make printing easier\r\n",
        "yhat = yhat.reshape((4, 4))\r\n",
        "\r\n",
        "# summarize output\r\n",
        "print(yhat)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 2. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [3. 0. 4. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exZeoRZ1-Hn1"
      },
      "source": [
        "*Unlike the UpSampling2D layer, the Conv2DTranspose will learn during training &  will attempt to fill in detail as part of the upsampling process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNO2W5NE-h1e"
      },
      "source": [
        "## Simple Generator Model With the Conv2DTranspose Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxTga5GXnRo5"
      },
      "source": [
        "The Conv2DTranspose is more complex than the UpSampling2D layer, but it is also effective when used in GAN models, specifically the generator model.\r\n",
        "\r\n",
        "In this example, our little GAN generator model must produce a 10×10 image and take a 100-element vector from the latent space as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uf4lEsE-mNv"
      },
      "source": [
        "# example of using transpose conv in a simple generator model\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Reshape\r\n",
        "from keras.layers import Conv2DTranspose\r\n",
        "from keras.layers import Conv2D"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWegjef1n2SX"
      },
      "source": [
        "# define model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# define input shape, output enough activations for for 128 5x5 image\r\n",
        "model.add(Dense(128 * 5 * 5, input_dim=100))\r\n",
        "\r\n",
        "# reshape vector of activations into 128 feature maps with 5x5\r\n",
        "model.add(Reshape((5, 5, 128)))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4ObhxRBn-Yu"
      },
      "source": [
        "Here, the 5×5 feature maps can be upsampled to a 10×10 feature map. We will use a 3×3 kernel size for the single filter, which will result in a slightly larger than doubled width and height in the output feature map (11×11)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqzy4u1Yn3uV",
        "outputId": "72bddd00-f27a-474c-9807-b8b3c35ca6cf"
      },
      "source": [
        "# double input from 128 5x5 to 1 10x10 feature map (set padding to 'same' to ensure these output dimensions)\r\n",
        "model.add(Conv2DTranspose(1, (3,3), strides=(2,2), padding='same'))\r\n",
        "\r\n",
        "# summarize model\r\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3200)              323200    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 10, 10, 1)         1153      \n",
            "=================================================================\n",
            "Total params: 324,353\n",
            "Trainable params: 324,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}